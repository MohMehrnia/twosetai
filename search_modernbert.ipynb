{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ae6183-38f8-40de-a021-e96227733c8c",
   "metadata": {},
   "source": [
    "# Document Search using ModernBERT and Milvus Vector DB\n",
    "\n",
    "![modernbert](images/modernbert.png)\n",
    "\n",
    "## Document Search using ModernBERT and Milvus Vector DB  \n",
    "\n",
    "**ModernBERT** builds upon the foundational success of BERT while incorporating advancements that address the evolving needs of real-world NLP tasks. As highlighted in [Hugging Face's blog on ModernBERT](https://huggingface.co/blog/modernbert), this model introduces several key improvements that make it particularly suitable for high-performance semantic search:  \n",
    "\n",
    "1. **Optimized Architecture:** ModernBERT employs techniques like disentangled attention and parallel layer computation, enabling it to generate embeddings faster and with lower computational costs compared to its predecessors.  \n",
    "2. **Enhanced Contextual Understanding:** With a deeper understanding of language semantics, ModernBERT can generate embeddings that better capture the meaning and relationships within and between documents, making it ideal for complex queries.  \n",
    "3. **Real-World Benchmarking:** ModernBERT is fine-tuned on diverse datasets and evaluated on real-world benchmarks, ensuring that it performs robustly across various applications, including search, classification, and clustering.  \n",
    "\n",
    "The motivation for choosing ModernBERT lies in its ability to bridge the gap between theoretical advancements in NLP and practical applications. Its embeddings are lightweight yet powerful, making it the ideal choice for scenarios where both speed and accuracy are critical, such as large-scale document retrieval.  \n",
    "\n",
    "Pairing ModernBERT with **Milvus**, a high-performance vector database, further amplifies its capabilities. Milvus enables efficient storage and retrieval of high-dimensional embeddings, ensuring that searches are not only semantically accurate but also fast and scalable. For datasets comprising thousands or millions of documents, this combination offers a transformative approach to semantic search.  \n",
    "\n",
    "### Basic System Architecture\n",
    "\n",
    "![system-design](images/system_design.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20426bd-0f15-4c81-ab79-f2afacd4a532",
   "metadata": {},
   "source": [
    "### Step 1: Setting Up the Environment\n",
    "\n",
    "Start by installing the necessary dependencies. We will need the following Python libraries:\n",
    "\n",
    "- `sentence-transformers` for generating embeddings.\n",
    "- `datasets` for loading the ML paper dataset.\n",
    "- `pymilvus` for interacting with the Milvus vector database.\n",
    "- `dotenv` for loading environment variables (e.g., API keys).\n",
    "\n",
    "You can install the required libraries via pip:\n",
    "\n",
    "```bash\n",
    "pip install sentence-transformers datasets pymilvus python-dotenv\n",
    "```\n",
    "\n",
    "#### Loading Environment Variables\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af636cc-2ae4-4cf2-90f6-12a94dc7abd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# load dot_env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff92efd-926a-4f25-bd46-b496a084ac17",
   "metadata": {},
   "source": [
    "### Step 2: Load the ModernBERT Model\n",
    "\n",
    "We will be using the `nomic-ai/modernbert-embed-base` model from the Sentence Transformers library. This model generates high-quality embeddings suitable for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5671604-bbe7-416a-8fba-1ffb2fee098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer(\"nomic-ai/modernbert-embed-base\")\n",
    "\n",
    "# Function to generate embeddings for a single text\n",
    "def generate_embeddings(text: str):\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84815455-abdb-477d-a83f-15c73e42fb7b",
   "metadata": {},
   "source": [
    "### Step 3: Prepare the Dataset\n",
    "\n",
    "We will use the \"CShorten/ML-ArXiv-Papers\" dataset from Hugging Face, which contains machine learning research papers, to demonstrate the document search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a90aac43-a8cc-4560-8d50-5811a4831de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"CShorten/ML-ArXiv-Papers\")\n",
    "     \n",
    "\n",
    "# Keep only \"title\" and \"abstract\" columns in train set\n",
    "train_ds = ds[\"train\"].select_columns([\"title\", \"abstract\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e520cff3-af94-40f8-a51e-1a47f1a98975",
   "metadata": {},
   "source": [
    "To work with a smaller subset for demo purposes, we will shuffle the dataset and select the first 1000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "896dc79d-53e4-4bcc-8629-1125e6c5808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1000\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset and select the first 100 rows\n",
    "small_dataset = train_ds.shuffle(seed=57).select(range(1000))\n",
    "\n",
    "query_prefix = \"search_query:\"\n",
    "document_prefix = \"search_document:\"\n",
    "\n",
    "# Concatenate abstract and titles\n",
    "def combine_text(row):\n",
    "    row[\"text\"] = document_prefix + \" \" + row[\"title\"] + \" \" + row[\"abstract\"]\n",
    "    return row\n",
    "\n",
    "# Apply function to entire dataset\n",
    "small_dataset = small_dataset.map(combine_text)\n",
    "\n",
    "# Print number of rows\n",
    "print(f\"Number of rows: {len(small_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff467c7-1f15-40d2-be4d-74529c791da6",
   "metadata": {},
   "source": [
    "### Step 4: Generate Embeddings for the Dataset\n",
    "\n",
    "Next, we define a function to generate embeddings for each document and apply it to the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b07af89-4c0a-4be3-8ddf-4c56149d5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings for a single text\n",
    "def generate_embeddings(example):\n",
    "    example[\"embeddings\"] = model.encode(example[\"text\"])\n",
    "    return example\n",
    "\n",
    "# Apply the function to the dataset using map\n",
    "embeddings_ds = small_dataset.map(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09718c6-df63-46fd-9c49-35776b7c3562",
   "metadata": {},
   "source": [
    "We can convert the dataset to a Pandas DataFrame for easier inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bfd7997-517d-46fd-ad63-78a6705f9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Active Learning Method for Diabetic Retinop...</td>\n",
       "      <td>In recent years, deep learning (DL) techniqu...</td>\n",
       "      <td>search_document: An Active Learning Method for...</td>\n",
       "      <td>[-0.029155258, -0.008791113, 0.009420881, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A general approximation lower bound in $L^p$ n...</td>\n",
       "      <td>We study the fundamental limits to the expre...</td>\n",
       "      <td>search_document: A general approximation lower...</td>\n",
       "      <td>[0.0038754004, -0.05021903, 0.0012840546, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TripleSpin - a generic compact paradigm for fa...</td>\n",
       "      <td>We present a generic compact computational f...</td>\n",
       "      <td>search_document: TripleSpin - a generic compac...</td>\n",
       "      <td>[0.046790063, -0.016866842, -0.016364306, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Self-Supervised Contrastive Learning for Unsup...</td>\n",
       "      <td>We propose a self-supervised representation ...</td>\n",
       "      <td>search_document: Self-Supervised Contrastive L...</td>\n",
       "      <td>[0.02431918, -0.035683442, -0.07060653, -0.071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparing learning algorithms in neural networ...</td>\n",
       "      <td>Today data mining techniques are exploited i...</td>\n",
       "      <td>search_document: Comparing learning algorithms...</td>\n",
       "      <td>[-0.03197413, -0.019541739, 0.043272045, -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  An Active Learning Method for Diabetic Retinop...   \n",
       "1  A general approximation lower bound in $L^p$ n...   \n",
       "2  TripleSpin - a generic compact paradigm for fa...   \n",
       "3  Self-Supervised Contrastive Learning for Unsup...   \n",
       "4  Comparing learning algorithms in neural networ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    In recent years, deep learning (DL) techniqu...   \n",
       "1    We study the fundamental limits to the expre...   \n",
       "2    We present a generic compact computational f...   \n",
       "3    We propose a self-supervised representation ...   \n",
       "4    Today data mining techniques are exploited i...   \n",
       "\n",
       "                                                text  \\\n",
       "0  search_document: An Active Learning Method for...   \n",
       "1  search_document: A general approximation lower...   \n",
       "2  search_document: TripleSpin - a generic compac...   \n",
       "3  search_document: Self-Supervised Contrastive L...   \n",
       "4  search_document: Comparing learning algorithms...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.029155258, -0.008791113, 0.009420881, -0.0...  \n",
       "1  [0.0038754004, -0.05021903, 0.0012840546, 0.02...  \n",
       "2  [0.046790063, -0.016866842, -0.016364306, -0.0...  \n",
       "3  [0.02431918, -0.035683442, -0.07060653, -0.071...  \n",
       "4  [-0.03197413, -0.019541739, 0.043272045, -0.00...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert HF dataset to Pandas DF\n",
    "df = embeddings_ds.to_pandas()\n",
    "\n",
    "# Take a peek at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2da40aa1-21c9-4626-a5a1-c64e745bb705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max text length: 2127\n"
     ]
    }
   ],
   "source": [
    "# get the max length of the text. column from pd dataframe\n",
    "# df[\"text_length\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "df['text_length'] = df['text'].str.len()\n",
    "\n",
    "max_text_length = int(df[\"text_length\"].max())\n",
    "print(f\"Max text length: {max_text_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16eeb8-6ea7-4b4e-97ab-ed210f0e7060",
   "metadata": {},
   "source": [
    "# Milvus Vector Database\n",
    "\n",
    "![milvus](images/milvus.png)\n",
    "\n",
    "### Step 5: Set Up the Milvus Vector Database\n",
    "\n",
    "Now, we will set up the Milvus vector database to store and search the embeddings. Milvus is an open-source vector database optimized for fast similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70bb2b32-cd87-418c-93b8-b00d32bb0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "\n",
    "# client = MilvusClient(\"papers.db\")\n",
    "\n",
    "client = MilvusClient(\n",
    "    uri=\"http://localhost:19530\"\n",
    ")\n",
    "\n",
    "# Create schema\n",
    "schema = MilvusClient.create_schema(\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    ")\n",
    "\n",
    "collection_name = \"modernbert_search\"\n",
    "\n",
    "# Add fields to schema\n",
    "schema.add_field(field_name=\"pk\", datatype=DataType.VARCHAR, is_primary=True, max_length=100)\n",
    "schema.add_field(field_name=\"text\", datatype=DataType.VARCHAR, max_length=max_text_length)\n",
    "schema.add_field(field_name=\"dense_vector\", datatype=DataType.FLOAT_VECTOR, dim=768)\n",
    "\n",
    "# Prepare index parameters \n",
    "index_params = client.prepare_index_params()\n",
    "\n",
    "# Add index\n",
    "index_params.add_index(\n",
    "    field_name=\"dense_vector\", \n",
    "    index_type=\"AUTOINDEX\",\n",
    "    metric_type=\"COSINE\"\n",
    ")\n",
    "\n",
    "if client.has_collection(collection_name):\n",
    "    client.drop_collection(collection_name)\n",
    "\n",
    "# Create collection with index loaded\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    schema=schema,\n",
    "    index_params=index_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5e68a4c-082e-4f32-a5e0-70bb1b995bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.has_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbb160-4a68-4864-8514-41d4d438f3ff",
   "metadata": {},
   "source": [
    "### Step 6: Insert Data into Milvus\n",
    "\n",
    "Now that we've set up the Milvus collection, we can insert the embeddings and their corresponding text into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0797d48a-c01d-48de-b592-cd21146cf3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 31.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(embeddings_ds), 50)):\n",
    "    batch_data = [\n",
    "        {\n",
    "            \"text\": title,\n",
    "            \"dense_vector\": embedding\n",
    "        }\n",
    "        for title, embedding in zip(\n",
    "            embeddings_ds[i : i + 50][\"title\"],\n",
    "            embeddings_ds[i : i + 50][\"embeddings\"]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    client.insert(\n",
    "        collection_name=collection_name,\n",
    "        data=batch_data\n",
    "    )\n",
    "# print(\"Number of entities inserted:\", col.num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a506d6c-ced8-46f6-88de-305f090ecfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active learning methods for diabetic retinopathy classification using Bayesian CNN\n"
     ]
    }
   ],
   "source": [
    "# Enter your search query\n",
    "query = \"Active learning methods for diabetic retinopathy classification using Bayesian CNN\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011096d-b7ef-435e-8f87-cfa28658fba5",
   "metadata": {},
   "source": [
    "### Step 7: Perform a Search Query\n",
    "\n",
    "Once the data is inserted into Milvus, we can perform a similarity search to find documents that match a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95d48b6a-9a15-4b08-9e28-712f026f811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymilvus import (AnnSearchRequest, WeightedRanker)\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def dense_search(query, limit=10):\n",
    "    query_embeddings = model.encode(query_prefix + \" \" + query)\n",
    "    res = client.search(\n",
    "        collection_name=\"modernbert_search\",  # Add collection name\n",
    "        data=[query_embeddings],\n",
    "        anns_field=\"dense_vector\",\n",
    "        limit=limit,\n",
    "        output_fields=[\"text\"],\n",
    "        search_params={\"metric_type\": \"COSINE\"}\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68d1a2ff-8a44-474e-bbe3-69a3a6a42895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title:** An Active Learning Method for Diabetic Retinopathy Classification with\n",
       "  Uncertainty Quantification,\n",
       "**Score:** 0.8416206240653992\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** Learn to Segment Retinal Lesions and Beyond,\n",
       "**Score:** 0.6053228378295898\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** Learning Discriminative Bayesian Networks from High-dimensional\n",
       "  Continuous Neuroimaging Data,\n",
       "**Score:** 0.572968065738678\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** Blood Vessel Detection using Modified Multiscale MF-FDOG Filters for\n",
       "  Diabetic Retinopathy,\n",
       "**Score:** 0.5701384544372559\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** Deep Active Learning for Axon-Myelin Segmentation on Histology Data,\n",
       "**Score:** 0.5581481456756592\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** DeepBrain: Functional Representation of Neural In-Situ Hybridization\n",
       "  Images for Gene Ontology Classification Using Deep Convolutional Autoencoders,\n",
       "**Score:** 0.5342372059822083\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** A Black-box Adversarial Attack Strategy with Adjustable Sparsity and\n",
       "  Generalizability for Deep Image Classifiers,\n",
       "**Score:** 0.5283135175704956\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** AdvFilter: Predictive Perturbation-aware Filtering against Adversarial\n",
       "  Attack via Multi-domain Learning,\n",
       "**Score:** 0.5278029441833496\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** Evaluation of Big Data based CNN Models in Classification of Skin\n",
       "  Lesions with Melanoma,\n",
       "**Score:** 0.5260496139526367\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** Minimax Active Learning,\n",
       "**Score:** 0.5215473175048828\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = dense_search(query)\n",
    "for hit in result[0]:\n",
    "    display(Markdown(f\"**Title:** {hit['entity']['text']},\\n**Score:** {hit['distance']}\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfc0d2-5841-4cc2-bcbd-4fc86222df3a",
   "metadata": {},
   "source": [
    "### Step 8: Generating Synthetic Queries\n",
    "\n",
    "We can generate synthetic queries and evaluation questions to aid in the search process. These queries can be used for type-ahead suggestions or to evaluate search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e972226a-8e81-4ab6-9984-d4aaae253fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_generation_prompt = \"\"\"\n",
    "You are an AI expert skilled in creating semantic search queries and evaluation questions for scientific content. \n",
    "Based on the given title and abstract of a machine learning research paper, generate a set of synthetic queries and questions. \n",
    "These should help users search for or evaluate the paper in a semantic search system.\n",
    "\n",
    "**Requirements:**\n",
    "1. Generate **1-3 synthetic queries** that a user might type into a search bar to find this paper. These queries should:\n",
    "   - Be varied in phrasing and focus on different aspects of the paper (e.g., problem addressed, methods used, results, applications, etc.).\n",
    "   - Use natural language and keywords relevant to the paper's topic.\n",
    "\n",
    "2. Generate **1-3 evaluation questions** that can help assess the relevance of search results to this paper. These questions should:\n",
    "   - Focus on the key contributions, concepts, or applications discussed in the paper.\n",
    "   - Be clear and relevant to researchers interested in this topic.\n",
    "\n",
    "3. Provide the output in JSON format with the following structure:\n",
    "```json\n",
    "{\n",
    "    \"synthetic_queries\": [\n",
    "    \"Query 1\",\n",
    "    \"Query 2\",\n",
    "    \"... (up to 3 queries)\"\n",
    "  ],\n",
    "  \"evaluation_questions\": [\n",
    "    \"Question 1\",\n",
    "    \"Question 2\",\n",
    "    \"... (up to 3 questions)\"\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c4226b91-a147-4aeb-b762-5e00c15e67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 100/100 [08:16<00:00,  4.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "import json\n",
    "\n",
    "items = df['text'].tolist()\n",
    "\n",
    "all_queries = []\n",
    "for item in tqdm(items[:100]):\n",
    "    response = completion(\n",
    "        model=\"mistral/mistral-large-2407\",\n",
    "        api_key=\"API_KEY\", # OR Read via env variables\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"{query_generation_prompt.strip()}\\n\\nPaper Title and Abstract:\\n {item}\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    queries = json.loads(response.choices[0].message.content)\n",
    "    all_queries.extend(queries['synthetic_queries'] + queries['evaluation_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e37f2ed3-e34f-44f0-9671-5b059fd7ab99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'synthetic_queries': ['How does the proposed method for diabetic retinopathy classification utilize active learning and uncertainty quantification?',\n",
       "  'What are the benefits of using a Bayesian convolutional neural network in medical imaging tasks?',\n",
       "  'Can you explain the challenges faced in annotating medical data and how this research addresses them?'],\n",
       " 'evaluation_questions': ['What key techniques are employed in the proposed hybrid model for improving diabetic retinopathy classification?',\n",
       "  'How does the paper measure the performance of its proposed framework compared to existing methods?',\n",
       "  'What insights does the study provide regarding the transparency and interpretability of deep learning models in medical applications?']}"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n",
    "json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "31a23cd3-d5ad-41f9-b667-7040e176f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_queries.txt', 'w') as f:\n",
    "    for query in all_queries:\n",
    "        f.write(f\"{query}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb949316-3b23-4bc9-8997-398c12515d5e",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this tutorial, we demonstrated how to set up a document search system using ModernBERT for embedding generation and Milvus for storing and querying those embeddings. We also explored the use of synthetic queries to enhance the search experience and evaluation. This setup can be extended for larger datasets and used in various real-world applications such as academic paper search or document retrieval systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72279335-7e2c-42f2-8d8e-89aa0cebb140",
   "metadata": {},
   "source": [
    "## Note: the full application (backend and frontend) is available here: https://github.com/mallahyari/modernbert-semantic-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c85b8f-9fae-4414-82e4-16be9b3a5b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
