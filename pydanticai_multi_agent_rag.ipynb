{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82712d0a-d4e6-4997-a0f4-e62227d9fdfc",
   "metadata": {},
   "source": [
    "# How to Implement Multi Agent RAG System (Agentic RAG) via PydanticAI\n",
    "\n",
    "**System architecture of a multi-agent RAG system**\n",
    "\n",
    "![mu](multi-agent-rag.png)\n",
    "<!-- <img src=\"https://weaviate.io/assets/images/Multi_Agent_RAG_System-73e480f62a52e172a78a0ac344dcdcb5.png\" alt=\"mu\" width=\"800\"> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b69126-7171-4a34-839f-846691df178d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "# Because we run the code in Jupyter lab, but not needed in production\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "# gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce35cfd-c543-4d18-95b3-2248d78c7c92",
   "metadata": {},
   "source": [
    "# PydanticAI Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758f2a9-186d-495b-a07f-7be0b8261db2",
   "metadata": {},
   "source": [
    "## Define an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "24581e0b-3d66-4873-8637-d8cde98cd6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It originated in early computer programming tutorials.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(  \n",
    "    'gemini-1.5-flash-8b',\n",
    "    system_prompt='Be concise, reply with one sentence.',  \n",
    ")\n",
    "\n",
    "result = agent.run_sync('Where does \"hello world\" come from?')  \n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "f266eb70-4b63-4fcc-9b68-757d109feef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello, World!\" originated from the 1972 programming language tutorial in the book \"The C Programming Language\" by Brian Kernighan and Dennis Ritchie.\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "model = OpenAIModel('gpt-4o-mini')\n",
    "agent = Agent(model, system_prompt='Be concise, reply with one sentence.')\n",
    "\n",
    "result = agent.run_sync('Where does \"hello world\" come from?')  \n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "edeed369-6a77-4eca-bd3d-2afd4a8198a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The phrase \"hello, world\" originated from the 1972 programming language \"BCPL\" as a simple standard output example, later popularized in the 1978 book \"The C Programming Language\" by Brian Kernighan and Dennis Ritchie, where it was used as the introductory program to demonstrate the syntax and capabilities of the C language; since then, it has become a universal first program for computer programmers learning new languages, symbolizing the beginning of one's journey into programming and serving as a rite of passage that encapsulates the transition from learner to coder, thus ingraining itself deeply within computing culture and education."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model = 'openai:gpt-4o-mini'\n",
    "\n",
    "\n",
    "@agent.system_prompt\n",
    "async def get_system_prompt(self) -> str:\n",
    "    return \"Give a long one paragraph answer and make it dense\"\n",
    "\n",
    "\n",
    "result = agent.run_sync('Where does \"hello world\" come from?')\n",
    "Markdown(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c11e9e03-cf84-4986-9ed6-393b3d84af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunlight scattering off air molecules causes blue light to be more visible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent, ModelRetry\n",
    "\n",
    "agent = Agent(\n",
    "    'gemini-1.5-flash-8b',\n",
    "    system_prompt='Be very concise, reply with one sentence only.',\n",
    "    retries=3\n",
    ")\n",
    "\n",
    "result = agent.run_sync('Why is the sky blue?')\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7975edd9-447e-4db9-847d-2b2e1c632151",
   "metadata": {},
   "source": [
    "## Basic Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "f050f132-df88-462c-917a-4c7fd13605bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: openai:gpt-4o-mini\n",
      "city='Chicago' country='USA' population=2716000\n",
      "Cost(request_tokens=73, response_tokens=40, total_tokens=113, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0})\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models import KnownModelName\n",
    "\n",
    "\n",
    "class CityInfo(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "    population: int\n",
    "\n",
    "\n",
    "model = 'openai:gpt-4o-mini'\n",
    "print(f'Using model: {model}')\n",
    "agent = Agent(model, result_type=CityInfo)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = agent.run_sync('The windy city in the US of America.')\n",
    "    print(result.data)\n",
    "    print(result.cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "77b0e0ca-e687-45ad-8591-3baf8d820797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city='San Francisco' country='United States' population=883305\n"
     ]
    }
   ],
   "source": [
    "result = agent.run_sync('Sanfransisco')\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf52bcea-9178-4328-b638-96de52ea931c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USA'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data.country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b16cb-b7bd-4daa-87a6-13d7b29a973d",
   "metadata": {},
   "source": [
    "## Chatbot App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e0db765-b639-47ee-8658-c06e87a954b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance from Atlanta, Georgia, to New York City varies depending on the mode of transportation. \n",
      "\n",
      "- **By air**, the direct flight distance is approximately 760 miles (1,225 kilometers).\n",
      "- **By road**, the driving distance is around 850 miles (1,368 kilometers), depending on the route taken.\n",
      "\n",
      "Travel times will vary based on traffic and the specific starting and ending points. If you have a specific location in either city, I can provide a more precise distance.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent('openai:gpt-4o-mini', system_prompt='Be a helpful assistant.')\n",
    "\n",
    "result = agent.run_sync(\"how far is it from my city Atlanta to New York?\")\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "916ec46d-38e7-4928-aaed-2b51df941f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemPrompt(content='Be a helpful assistant.', role='system'),\n",
       " UserPrompt(content='how far is it from my city Atlanta to New York?', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 28, 746716, tzinfo=datetime.timezone.utc), role='user'),\n",
       " ModelTextResponse(content='The distance from Atlanta, Georgia, to New York City varies depending on the mode of transportation. \\n\\n- **By air**, the direct flight distance is approximately 760 miles (1,225 kilometers).\\n- **By road**, the driving distance is around 850 miles (1,368 kilometers), depending on the route taken.\\n\\nTravel times will vary based on traffic and the specific starting and ending points. If you have a specific location in either city, I can provide a more precise distance.', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 28, tzinfo=datetime.timezone.utc), role='model-text-response')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41c073ae-6d2f-4fab-802e-ebea8c9a06f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserPrompt(content='how far is it from my city Atlanta to New York?', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 28, 746716, tzinfo=datetime.timezone.utc), role='user'),\n",
       " ModelTextResponse(content='The distance from Atlanta, Georgia, to New York City varies depending on the mode of transportation. \\n\\n- **By air**, the direct flight distance is approximately 760 miles (1,225 kilometers).\\n- **By road**, the driving distance is around 850 miles (1,368 kilometers), depending on the route taken.\\n\\nTravel times will vary based on traffic and the specific starting and ending points. If you have a specific location in either city, I can provide a more precise distance.', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 28, tzinfo=datetime.timezone.utc), role='model-text-response')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.new_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08ed0e94-890e-44df-8f19-bb5f13f9cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance from Atlanta, Georgia, to Boston, Massachusetts, also varies by mode of transportation:\n",
      "\n",
      "- **By air**, the direct flight distance is approximately 900 miles (1,450 kilometers).\n",
      "- **By road**, the driving distance is around 1,000 miles (1,609 kilometers), depending on the specific route taken.\n",
      "\n",
      "As with the previous distance, travel times can vary based on traffic conditions and the exact starting and ending locations. Let me know if you need more specific information!\n"
     ]
    }
   ],
   "source": [
    "result2 = agent.run_sync('how about to Boston?', message_history=result.new_messages())\n",
    "print(result2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21fcbd0a-e82a-4d41-a971-a889e1837156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemPrompt(content='Be a helpful assistant.', role='system'),\n",
       " UserPrompt(content='how far is it from my city Atlanta to New York?', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 28, 746716, tzinfo=datetime.timezone.utc), role='user'),\n",
       " ModelTextResponse(content='The distance from Atlanta, Georgia, to New York City varies depending on the mode of transportation. \\n\\n- **By air**, the direct flight distance is approximately 760 miles (1,225 kilometers).\\n- **By road**, the driving distance is around 850 miles (1,368 kilometers), depending on the route taken.\\n\\nTravel times will vary based on traffic and the specific starting and ending points. If you have a specific location in either city, I can provide a more precise distance.', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 28, tzinfo=datetime.timezone.utc), role='model-text-response'),\n",
       " UserPrompt(content='how about to Boston?', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 30, 748034, tzinfo=datetime.timezone.utc), role='user'),\n",
       " ModelTextResponse(content='The distance from Atlanta, Georgia, to Boston, Massachusetts, also varies by mode of transportation:\\n\\n- **By air**, the direct flight distance is approximately 900 miles (1,450 kilometers).\\n- **By road**, the driving distance is around 1,000 miles (1,609 kilometers), depending on the specific route taken.\\n\\nAs with the previous distance, travel times can vary based on traffic conditions and the exact starting and ending locations. Let me know if you need more specific information!', timestamp=datetime.datetime(2024, 12, 12, 20, 22, 30, tzinfo=datetime.timezone.utc), role='model-text-response')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.all_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b66017-fe2d-4c5e-9dac-b092f5760305",
   "metadata": {},
   "source": [
    "## Tool Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "f5939eaf-4bda-4c1a-9e00-2e5f9d7e41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext, Tool\n",
    "\n",
    "async def get_stock_price(ctx: RunContext[str], ticker: str) -> str:\n",
    "    # print(ctx)\n",
    "    # print(ticker)\n",
    "    return '$137.8'\n",
    "\n",
    "\n",
    "async def sum(ctx: RunContext[str], x:int, y: int) -> int:\n",
    "    print(f\"x: {x}, y:{y}\")\n",
    "    return x + y\n",
    "\n",
    "\n",
    "async def multiply(ctx: RunContext[str], x:int, y: int) -> int:\n",
    "    print(f\"x: {x}, y:{y}\")\n",
    "    return x * y\n",
    "\n",
    "agent = Agent('openai:gpt-4o-mini', system_prompt='Answer questions only using the tools you have.', \n",
    "              tools=[Tool(get_stock_price), Tool(sum), Tool(multiply)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "a1dcfaf2-8bdb-451b-b0a5-9e93a6ddb4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current stock price of Tesla (TSLA) is $137.8.\n"
     ]
    }
   ],
   "source": [
    "result = agent.run_sync('What is Tesla stock price')\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "260ad783-f4c9-448e-840c-2abed7a90d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 18, y:28\n",
      "The answer of \\( 18 \\times 28 \\) is 504.\n"
     ]
    }
   ],
   "source": [
    "result = agent.run_sync('what is the answer of 18 * 28')\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "c76fac44-89a9-479e-b2d2-9a09d0024f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(_all_messages=[SystemPrompt(content='Answer questions only using the tools you have.', role='system'), UserPrompt(content='what is the answer of 18 * 28', timestamp=datetime.datetime(2024, 12, 13, 19, 23, 10, 363837, tzinfo=datetime.timezone.utc), role='user'), ModelStructuredResponse(calls=[ToolCall(tool_name='multiply', args=ArgsJson(args_json='{\"x\":18,\"y\":28}'), tool_id='call_6cV1VdsSYwvexTfHs3pr8IvU')], timestamp=datetime.datetime(2024, 12, 13, 19, 23, 10, tzinfo=datetime.timezone.utc), role='model-structured-response'), ToolReturn(tool_name='multiply', content=504, tool_id='call_6cV1VdsSYwvexTfHs3pr8IvU', timestamp=datetime.datetime(2024, 12, 13, 19, 23, 11, 44703, tzinfo=datetime.timezone.utc), role='tool-return'), ModelTextResponse(content='The answer of \\\\( 18 \\\\times 28 \\\\) is 504.', timestamp=datetime.datetime(2024, 12, 13, 19, 23, 11, tzinfo=datetime.timezone.utc), role='model-text-response')], _new_message_index=1, data='The answer of \\\\( 18 \\\\times 28 \\\\) is 504.', _cost=Cost(request_tokens=235, response_tokens=34, total_tokens=269, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0}))"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1983c229-055d-40fe-8c96-144479a0bd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cost(request_tokens=235, response_tokens=34, total_tokens=269, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0})"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce74e4-6bc4-47a3-b0c5-e4aff3c91fb4",
   "metadata": {},
   "source": [
    "# Agentic RAG (Multi Agent RAG System)\n",
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "56d1deca-f113-44db-aa7f-dfa51c1125de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import json\n",
    "from typing import Optional\n",
    "import requests\n",
    "\n",
    "def fetch_url_content(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetches content from a URL by performing an HTTP GET request.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The endpoint or URL to fetch content from.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The content retrieved from the URL as a string,\n",
    "                       or None if the request fails.\n",
    "    \"\"\"\n",
    "    prefix_url: str = \"https://r.jina.ai/\"\n",
    "    full_url: str = prefix_url + url  # Concatenate the prefix URL with the provided URL\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(full_url)  # Perform a GET request\n",
    "        if response.status_code == 200:\n",
    "            return response.content.decode('utf-8')  # Return the content of the response as a string\n",
    "        else:\n",
    "            print(f\"Error: HTTP GET request failed with status code {response.status_code}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error: Failed to fetch URL {full_url}. Exception: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "6b9e22f2-a3a4-4c19-a4a1-75b1c641bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content retrieved successfully:\n"
     ]
    }
   ],
   "source": [
    "# Replace this with the specific endpoint or URL you want to fetch\n",
    "url = \"https://ai.meta.com/blog/meta-llama-3/\"  \n",
    "content: Optional[str] = fetch_url_content(url)\n",
    "\n",
    "\n",
    "if content is not None:\n",
    "    print(\"Content retrieved successfully:\")\n",
    "else:\n",
    "    print(\"Failed to retrieve content from the specified URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "f7763fa4-d123-4d77-ae2f-39dcea09e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "5ee4a841-d830-4201-917b-6d5d678074e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_size = 100\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            model_name=\"gpt-4\",\n",
    "            chunk_size=token_size,\n",
    "            chunk_overlap=0,\n",
    "        )\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove all newline characters\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Strip leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "e03e20c1-aafc-452e-97c1-61d59473ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 86\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_splitter.split_text(content)\n",
    "print(f\"Total chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "bb65f742-8eed-4458-9e01-de6c857a590d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Introducing Meta Llama 3: The most capable openly available LLM to date\\n\\nURL Source: https://ai.meta.com/blog/meta-llama-3/\\n\\nMarkdown Content:\\nTakeaways:\\n\\nRECOMMENDED READS'"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "3b8f3a33-3a1c-4d7d-8c70-1325d1e5d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model=\"text-embedding-3-small\", api_key=\"your-api-key\"):\n",
    "    # Define the API URL\n",
    "    url = \"https://api.openai.com/v1/embeddings\"\n",
    "    \n",
    "    # Prepare headers with the API key\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    # Prepare the request body\n",
    "    data = {\n",
    "        \"input\": texts,\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "    # Send a POST request to the OpenAI API\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Return the embeddings from the response\n",
    "        return response.json()[\"data\"]\n",
    "    else:\n",
    "        # Print error if the request fails\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "404730ae-c10a-42e4-8e28-f88d3a5d84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings_objects = get_embeddings(text_chunks, api_key=OPENAI_API_KEY)\n",
    "assert len(embeddings_objects) == len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "81d9a3cb-8df5-4a58-a493-ee98dd70fa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [obj[\"embedding\"] for obj in embeddings_objects]\n",
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "de971508-836f-4c73-af7a-06b839ae3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "1b9247db-53a4-4519-ae26-9b0509e1f1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"agent_rag_index\"\n",
    "VECTOR_SIZE = 1536\n",
    "\n",
    "client.delete_collection(collection_name)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "3ed56d4f-ba07-4099-99da-12c41c327cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ul': 'https://ai.meta.com/blog/meta-llama-3/',\n",
       " 'content': 'Title: Introducing Meta Llama 3: The most capable openly available LLM to date\\n\\nURL Source: https://ai.meta.com/blog/meta-llama-3/\\n\\nMarkdown Content:\\nTakeaways:\\n\\nRECOMMENDED READS'}"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "payload = []\n",
    "\n",
    "for id, text in enumerate(text_chunks):\n",
    "    ids.append(id)\n",
    "    payload.append({\"ul\": url, \"content\": text})\n",
    "\n",
    "payload[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "e670f331-5863-4671-b89d-8f372ef4133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors=embeddings,\n",
    "    payload=payload,\n",
    "    ids=ids,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "d6db7858-0382-43d3-b935-3f6eb64f1cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=86)"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.count(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a37d2-5828-42c3-8c01-3f8f80791bce",
   "metadata": {},
   "source": [
    "## Define Agents\n",
    "- RAG Agent\n",
    "- Router Agent\n",
    "- Web Search agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "ecda8a60-cf67-42a0-bf12-a2aa886af061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class RagDeps:\n",
    "    openai_api_key: str | None\n",
    "    client: QdrantClient\n",
    "    top_k: int = 3\n",
    "    \n",
    "\n",
    "async def search(ctx: RunContext[RagDeps], text: str):\n",
    "    query_embedding = get_embeddings(text, api_key=ctx.deps.openai_api_key)[0][\"embedding\"]\n",
    "    \n",
    "    search_result = ctx.deps.client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        query_filter=None,  \n",
    "        limit=ctx.deps.top_k\n",
    "    )\n",
    "    # print(f\"=====>results:{search_result}\")\n",
    "    context = format_docs(search_result)\n",
    "    return context\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.payload[\"content\"] for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "8f382058-a399-4a36-9bbc-fee45362e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert for answering questions. Answer the question according only to the given context.\n",
    "If question cannot be answered using the context, simply say I don't know. Do not make stuff up.\n",
    "Your answer MUST be informative, concise, and action driven. Your response must be in Markdown.\n",
    "\"\"\"\n",
    "\n",
    "deps = RagDeps(openai_api_key=OPENAI_API_KEY, client=client)\n",
    "\n",
    "rag_agent = Agent(name=\"retriever\", model='openai:gpt-4o-mini',\n",
    "                  deps_type=RagDeps,\n",
    "                  system_prompt=system_prompt, tools=[Tool(search)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "5e60b23e-63e0-425d-add9-d0198c48aef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Llama 3 is a collection of models designed to improve performance across core large language model (LLM) capabilities, such as reasoning and coding. The initial release includes the Llama 3 8B and 70B models. Future goals for Llama 3 include making it multilingual and multimodal, enhancing context length, and further improving overall performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = rag_agent.run_sync(\"what is llama3?\", deps=deps)\n",
    "\n",
    "display(Markdown(result.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "0b2dba92-d14d-4a90-857f-8d552ae3c049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cost(request_tokens=326, response_tokens=89, total_tokens=415, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0})"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db90669-6bc1-4a45-b988-853c105f9223",
   "metadata": {},
   "source": [
    "# Adding Router Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "bebf3e30-2756-4818-bbec-9637c4a2e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingDecision(BaseModel):\n",
    "    vector_search: bool = False\n",
    "    web_search: bool = False\n",
    "\n",
    "decision_system_prompt = \"\"\"Your job is decide if a given question needs vector search or web search.\n",
    "- Vector search is required if question is about Llama3\n",
    "- Web search is required if the question is about current events or real-time data\n",
    "\"\"\"\n",
    "\n",
    "router_agent = Agent(model='openai:gpt-4o', system_prompt=decision_system_prompt, result_type=RoutingDecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "14e8ed64-2d46-48db-a522-66b3021c3bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search=False web_search=True\n"
     ]
    }
   ],
   "source": [
    "question = \"How take a picture with three lamas animals?\"\n",
    "# question = \"what is the best time to travel to Florida?\"\n",
    "decision = router_agent.run_sync(question)\n",
    "print(decision.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "ce90b38a-fdf3-4364-a978-013183cf8b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "NVIDIA is an American multinational corporation that designs and supplies graphics processing units (GPUs), application programming interfaces (APIs) for data science and high-performance computing.  It's known for its graphics cards used in gaming and professional applications, as well as its role in artificial intelligence computing.  The provided text also mentions its GeForce RTX series for gaming and other applications.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "web_search_agent = Agent(model='gemini-1.5-flash-8b', system_prompt='Be a helpful assistant.')\n",
    "\n",
    "@web_search_agent.tool\n",
    "async def search_online(ctx: RunContext, query: str):\n",
    "    results = DDGS().text(query, max_results=5)\n",
    "    context = \"\\n\\n\".join(doc[\"body\"] for doc in results)\n",
    "    return context\n",
    "\n",
    "answer = web_search_agent.run_sync(\"Tell me about Nvidia?\")\n",
    "display(Markdown(answer.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "bf12b9b7-d86b-4ada-ba0f-6b39e2c9a43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Most people agree the best time to visit Florida is between March and April, or September and October.  The weather is pleasant, it's less crowded, and often cheaper. However, these months also coincide with the school year, so families with children may find other times better.  The best time ultimately depends on your priorities and budget.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if decision.data.vector_search:\n",
    "    result = rag_agent.run_sync(question, deps=deps)\n",
    "    display(Markdown(result.data))\n",
    "    result.cost()\n",
    "else:\n",
    "    answer = web_search_agent.run_sync(question)\n",
    "    display(Markdown(answer.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f96347-9f25-4816-b322-5e8de0476e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
